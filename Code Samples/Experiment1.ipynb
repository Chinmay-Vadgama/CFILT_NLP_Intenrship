{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Exp-1-T.Baldwin-&amp;-Su-Nam-Kim-NC-Experiment-Based-On-Wordnet-Similarity\" data-toc-modified-id=\"Exp-1-T.Baldwin-&amp;-Su-Nam-Kim-NC-Experiment-Based-On-Wordnet-Similarity-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Exp-1 T.Baldwin &amp; Su Nam Kim NC-Experiment Based On Wordnet Similarity</a></span><ul class=\"toc-item\"><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Reading-Data\" data-toc-modified-id=\"Reading-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Reading Data</a></span></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Find-Similarities\" data-toc-modified-id=\"Find-Similarities-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Find Similarities</a></span></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Checking-Results\" data-toc-modified-id=\"Checking-Results-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Checking Results</a></span></li></ul></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Parallel\" data-toc-modified-id=\"Parallel-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Parallel</a></span><ul class=\"toc-item\"><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Background\" data-toc-modified-id=\"Background-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Parallel-for-bkgrnd\" data-toc-modified-id=\"Parallel-for-bkgrnd-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Parallel for bkgrnd</a></span></li></ul></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Singular-Plural-noun-mapping\" data-toc-modified-id=\"Singular-Plural-noun-mapping-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Singular-Plural noun mapping</a></span><ul class=\"toc-item\"><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Using-predefined-fix-mapping\" data-toc-modified-id=\"Using-predefined-fix-mapping-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using predefined fix mapping</a></span></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Using-an-library\" data-toc-modified-id=\"Using-an-library-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Using an library</a></span></li></ul></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#New-Section\" data-toc-modified-id=\"New-Section-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>New Section</a></span></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#extracting-features-from-sentence\" data-toc-modified-id=\"extracting-features-from-sentence-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>extracting features from sentence</a></span><ul class=\"toc-item\"><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#verb_list\" data-toc-modified-id=\"verb_list-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>verb_list</a></span></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#Finding-common-ancestor\" data-toc-modified-id=\"Finding-common-ancestor-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Finding common ancestor</a></span></li></ul></li><li><span><a href=\"http://10.129.2.170:3904/notebooks/Experiment1.ipynb#TO-DO\" data-toc-modified-id=\"TO-DO-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>TO-DO</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp-1 T.Baldwin & Su Nam Kim NC-Experiment Based On Wordnet Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coalition</td>\n",
       "      <td>force</td>\n",
       "      <td>HAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary</td>\n",
       "      <td>form</td>\n",
       "      <td>HAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>system</td>\n",
       "      <td>INST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>door</td>\n",
       "      <td>HAVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>programme</td>\n",
       "      <td>ABOUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1      2\n",
       "0  coalition      force   HAVE\n",
       "1    summary       form   HAVE\n",
       "2   computer     system   INST\n",
       "3    kitchen       door   HAVE\n",
       "4      media  programme  ABOUT"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('SC08.all.txt',header=None,sep=' ',usecols=[0,1,2])\n",
    "data.dropna()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in data.values[-100:]:\n",
    "    if i[2] == 'purpose' :\n",
    "        count += 1\n",
    "count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "matrix = data.values\n",
    "\n",
    "#print matrix\n",
    "# it is known that data has 2168 rows we keep last 500 for test others are training set.\n",
    "\n",
    "limit = 100\n",
    "\n",
    "train_data = matrix[:-limit]\n",
    "test_data  = matrix[-limit:]\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "\n",
    "for i, test in (enumerate( test_data)):\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print i\n",
    "\n",
    "    test_m_syn = wn.synsets( test[0] )\n",
    "    test_h_syn = wn.synsets( test[1] )\n",
    "    if test_m_syn and test_h_syn:\n",
    "        test_m_syn = test_m_syn[0]\n",
    "        test_h_syn = test_h_syn[0]\n",
    "    else:\n",
    "       # print i, test\n",
    "        continue\n",
    "\n",
    "    best_score = -10\n",
    "    best_label = ''\n",
    "    for j, train in enumerate(train_data):\n",
    "                \n",
    "        train_m_syn = wn.synsets( train[0] )\n",
    "        train_h_syn = wn.synsets( train[1] )\n",
    "        if train_m_syn and train_h_syn:\n",
    "            train_m_syn = train_m_syn[0]\n",
    "            train_h_syn = train_h_syn[0]\n",
    "        else:\n",
    "            #print j, train\n",
    "            continue\n",
    "        \n",
    "        m = train_m_syn.wup_similarity( test_m_syn )\n",
    "        h = train_h_syn.wup_similarity( test_h_syn )\n",
    "        \n",
    "        if not m or not h:\n",
    "            #print test_m_syn, test_h_syn, train_m_syn, train_h_syn\n",
    "            #print i, j, m, h, test, train\n",
    "            continue\n",
    "            \n",
    "        score = (m + h) / 2\n",
    "        if score > best_score:\n",
    "            best_label = train[2]\n",
    "            best_score = score\n",
    "            \n",
    "    true_labels.append( test[2] )\n",
    "    pred_labels.append( best_label )\n",
    "        #print(m,\" \",h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for t, p in zip(true_labels, pred_labels):\n",
    "    if t == p:\n",
    "        count += 1\n",
    "        \n",
    "len(true_labels), count\n",
    "print (count*1.)/len(true_labels)\n",
    "print len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This is good when we have single labels for test and prediction\n",
    "# This will not work 'as expected' in case we have multiple labels possible.\n",
    "'''\n",
    "true_np = np.array( true_labels )\n",
    "pred_np = np.array( pred_labels )\n",
    "\n",
    "(true_np == pred_np).sum() * 1. / true_np.shape[0]\n",
    "'''\n",
    "#set(true_labels)\n",
    "#set(pred_labels)\n",
    "#Code for multiple labels\n",
    "\n",
    "count = 0\n",
    "for i, j in zip(true_labels, pred_labels):\n",
    "\n",
    "        if set( i.split('/') ).intersection( set(j.split('/')) ):\n",
    "            count += 1\n",
    "count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print len(true_labels)\n",
    "print len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ABOUT     0.6471    0.6471    0.6471        17\n",
      "      ACTOR     0.6667    0.6667    0.6667        21\n",
      "         BE     0.3846    0.6250    0.4762         8\n",
      "       HAVE     0.2857    0.3333    0.3077        12\n",
      "         IN     0.5263    0.3704    0.4348        27\n",
      "       INST     0.4375    0.4667    0.4516        15\n",
      "\n",
      "avg / total     0.5228    0.5100    0.5102       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(true_labels, pred_labels, digits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-9854e9761fb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mc4\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc4\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mrec\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc4\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mfscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprec\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprec\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "#checking results for purpose tag.\n",
    "result = zip(pred_labels , true_labels)\n",
    "result\n",
    "c1=0\n",
    "c2=0\n",
    "c3=0\n",
    "c4=0\n",
    "for i in result :\n",
    "    #false-neg\n",
    "    if i[0] != 'purpose' and i[1]=='purpose':\n",
    "        c1+=1\n",
    "    #true-neg\n",
    "    elif not(i[0]=='purpose') and not(i[1]=='purpose'):\n",
    "        c2+=1\n",
    "    #false-pos\n",
    "    elif (i[0]=='purpose') and not(i[1]=='purpose'):\n",
    "        c3+=1\n",
    "    #true-pos\n",
    "    else:\n",
    "        c4+=1\n",
    "prec = (c4 * 1.) / (c4+c3)\n",
    "rec  = (c4 * 1.) / (c4+c1)\n",
    "fscore = (2.*prec * rec) / (prec+rec)\n",
    "print('prec ',prec)\n",
    "print('rec',rec)\n",
    "print('fscore',fscore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set(true_labels)\n",
    "set(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#true_labels = ['1', 'agent', 'b', 'agent', 'f', 'a', 'b', '1', '2', '2', '2', '1']\n",
    "#pred_labels = ['a', 'agent', 'a', 'agent', 'f', 'f', 'b', '1', '3', '2', 'agent', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_labels = set(true_labels).union( set(pred_labels) )\n",
    "all_labels = list(all_labels)\n",
    "all_labels.sort()\n",
    "print all_labels\n",
    "conf = confusion_matrix(true_labels, pred_labels, labels=all_labels)\n",
    "print conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(conf, columns=all_labels)\n",
    "df.index = all_labels\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_labels = set(['w', 1,2,3]).union( set([2,4,5, 'a']) )\n",
    "print all_labels\n",
    "all_labels = list(all_labels)\n",
    "all_labels.sort()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamd_fun = lambda a, b: a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lamd_fun(i, i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 11, 24, 39, 56, 75, 96, 119, 144, 171]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lamd_fun, range(10), range(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 12, 14, 16, 18, 20, 22, 24, 26, 28]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda i, j: i+j, range(10), range(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda i, j: i+j, range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel for bkgrnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(train_nc):\n",
    "    \n",
    "    if not test_m_syn or not test_h_syn:\n",
    "        return -10, ''\n",
    "\n",
    "    train_m_syn = wn.synsets( train_nc[0] )\n",
    "    train_h_syn = wn.synsets( train_nc[1] )\n",
    "    if train_m_syn and train_h_syn:\n",
    "        train_m_syn = train_m_syn[0]\n",
    "        train_h_syn = train_h_syn[0]\n",
    "    else:\n",
    "        return -10, ''\n",
    "\n",
    "    m = train_m_syn.wup_similarity( test_m_syn )\n",
    "    h = train_h_syn.wup_similarity( test_h_syn )\n",
    "\n",
    "    if not m or not h:\n",
    "        return -10, ''\n",
    "    \n",
    "    score = (m + h) / 2\n",
    "    \n",
    "    return score, train_nc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.20526315789473684, 'agent')\n",
      "(-10, '')\n"
     ]
    }
   ],
   "source": [
    "print fun(['worker', 'protest', 'agent'])\n",
    "print fun(['Hongkong', 'protest', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5707070707070707, 'topic')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nc = 'student protest'\n",
    "d = map(fun, train_data)\n",
    "result = reduce(lambda x, y: x if x[0] > y[0] else y, d)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:47<00:00,  2.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7602339181286549, 'BE'),\n",
       " (0.7105263157894737, 'IN'),\n",
       " (0.9285714285714286, 'HAVE'),\n",
       " (0.9285714285714286, 'BE'),\n",
       " (0.6875, 'IN'),\n",
       " (0.76890756302521, 'IN'),\n",
       " (0.7738095238095238, 'IN'),\n",
       " (0.6787330316742082, 'ACTOR'),\n",
       " (0.7424242424242424, 'ACTOR'),\n",
       " (0.8455882352941176, 'IN'),\n",
       " (0.8095238095238095, 'INST'),\n",
       " (0.6458333333333333, 'HAVE'),\n",
       " (0.6428571428571428, 'HAVE'),\n",
       " (0.6666666666666666, 'IN'),\n",
       " (0.7733333333333333, 'ACTOR'),\n",
       " (0.8333333333333333, 'ABOUT'),\n",
       " (0.5833333333333333, 'ACTOR'),\n",
       " (0.7, 'ABOUT'),\n",
       " (0.7948717948717949, 'ACTOR'),\n",
       " (0.7272727272727273, 'IN'),\n",
       " (0.6907894736842105, 'ABOUT'),\n",
       " (0.8585526315789473, 'ACTOR'),\n",
       " (0.7, 'INST'),\n",
       " (0.8125, 'IN'),\n",
       " (0.8285714285714285, 'ACTOR'),\n",
       " (0.8529411764705883, 'ACTOR'),\n",
       " (0.7386363636363636, 'ABOUT'),\n",
       " (0.7246963562753037, 'HAVE'),\n",
       " (0.8157894736842105, 'ACTOR'),\n",
       " (0.7602339181286549, 'IN'),\n",
       " (0.8, 'IN'),\n",
       " (0.6936274509803921, 'INST'),\n",
       " (0.6805555555555556, 'INST'),\n",
       " (0.6491228070175439, 'HAVE'),\n",
       " (0.7291666666666667, 'BE'),\n",
       " (0.8, 'HAVE'),\n",
       " (0.7222222222222222, 'BE'),\n",
       " (0.7357142857142858, 'ABOUT'),\n",
       " (0.6428571428571428, 'ABOUT'),\n",
       " (0.7380952380952381, 'INST'),\n",
       " (0.75, 'BE'),\n",
       " (0.6764705882352942, 'BE'),\n",
       " (0.6461988304093567, 'BE'),\n",
       " (0.7, 'ACTOR'),\n",
       " (0.7232142857142857, 'IN'),\n",
       " (0.8125, 'ABOUT'),\n",
       " (0.7321428571428572, 'ACTOR'),\n",
       " (0.6974789915966386, 'INST'),\n",
       " (0.8571428571428572, 'ACTOR'),\n",
       " (0.7177033492822966, 'IN'),\n",
       " (0.9, 'ACTOR'),\n",
       " (0.7777777777777778, 'HAVE'),\n",
       " (0.6875, 'ABOUT'),\n",
       " (0.7543859649122806, 'BE'),\n",
       " (0.696969696969697, 'ABOUT'),\n",
       " (0.6798245614035088, 'INST'),\n",
       " (0.9545454545454546, 'HAVE'),\n",
       " (0.3216374269005848, 'INST'),\n",
       " (0.6666666666666666, 'INST'),\n",
       " (0.7727272727272727, 'ABOUT'),\n",
       " (0.7846153846153847, 'BE'),\n",
       " (0.6971153846153846, 'INST'),\n",
       " (0.7727272727272727, 'BE'),\n",
       " (0.6666666666666666, 'ABOUT'),\n",
       " (0.75, 'ACTOR'),\n",
       " (0.8125, 'IN'),\n",
       " (0.7941176470588236, 'ABOUT'),\n",
       " (0.8012820512820513, 'INST'),\n",
       " (0.7083333333333333, 'IN'),\n",
       " (0.7727272727272727, 'BE'),\n",
       " (0.7727272727272727, 'HAVE'),\n",
       " (0.6578947368421053, 'INST'),\n",
       " (0.6833333333333333, 'IN'),\n",
       " (0.8888888888888888, 'HAVE'),\n",
       " (0.6654411764705883, 'BE'),\n",
       " (0.8125, 'INST'),\n",
       " (0.868421052631579, 'IN'),\n",
       " (0.6818181818181819, 'HAVE'),\n",
       " (0.6052631578947368, 'INST'),\n",
       " (0.6157894736842104, 'ACTOR'),\n",
       " (0.7166666666666667, 'HAVE'),\n",
       " (0.8666666666666667, 'ACTOR'),\n",
       " (0.660633484162896, 'ACTOR'),\n",
       " (0.7733333333333333, 'ACTOR'),\n",
       " (0.8125, 'IN'),\n",
       " (0.7045454545454546, 'ABOUT'),\n",
       " (0.6538461538461539, 'HAVE'),\n",
       " (0.6752136752136753, 'ABOUT'),\n",
       " (0.8125, 'BE'),\n",
       " (0.618421052631579, 'IN'),\n",
       " (0.6727941176470589, 'INST'),\n",
       " (0.6818181818181819, 'HAVE'),\n",
       " (0.8071428571428572, 'IN'),\n",
       " (0.8545454545454545, 'ACTOR'),\n",
       " (0.7307692307692308, 'INST'),\n",
       " (0.5791666666666666, 'IN'),\n",
       " (0.7543859649122806, 'ACTOR'),\n",
       " (0.7666666666666666, 'ABOUT'),\n",
       " (0.7125, 'ABOUT'),\n",
       " (0.7004048582995952, 'ABOUT')]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = []\n",
    "train_data = matrix[:-limit]\n",
    "test_data  = matrix[-limit:]\n",
    "for test_nc in tqdm(test_data):\n",
    "    test_m_syn = wn.synsets( test_nc[0] )\n",
    "    test_h_syn = wn.synsets( test_nc[1] )\n",
    "    if test_m_syn and test_h_syn:\n",
    "        test_m_syn = test_m_syn[0]\n",
    "        test_h_syn = test_h_syn[0]\n",
    "        \n",
    "        d = map(fun, train_data)\n",
    "        result = reduce(lambda x, y: x if x[0] > y[0] else y, d)\n",
    "        \n",
    "    else:\n",
    "        result = (-10, '')\n",
    "    pred_labels.append( result )\n",
    "    \n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "pred_lb = []\n",
    "true_lb = []\n",
    "for i in pred_labels:\n",
    "    pred_lb.append(i[1])\n",
    "print len(pred_lb)\n",
    "print len(true_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      ABOUT     0.6471    0.6471    0.6471        17\n",
      "      ACTOR     0.6500    0.6190    0.6341        21\n",
      "         BE     0.3846    0.6250    0.4762         8\n",
      "       HAVE     0.2857    0.3333    0.3077        12\n",
      "         IN     0.5000    0.3704    0.4255        27\n",
      "       INST     0.4375    0.4667    0.4516        15\n",
      "\n",
      "avg / total     0.5122    0.5000    0.5008       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(true_labels, pred_lb, digits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['BE', 'ABOUT', 'ACTOR', 'INST', 'HAVE', 'IN'])\n",
      "set(['BE', 'ABOUT', 'ACTOR', 'INST', 'HAVE', 'IN'])\n"
     ]
    }
   ],
   "source": [
    "print set(true_labels) \n",
    "print set(pred_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABOUT', 'ACTOR', 'BE', 'HAVE', 'IN', 'INST']\n",
      "[[11  0  1  0  2  3]\n",
      " [ 1 13  1  2  4  0]\n",
      " [ 0  0  5  1  1  1]\n",
      " [ 1  2  2  4  1  2]\n",
      " [ 3  3  4  4 10  3]\n",
      " [ 1  2  0  3  2  7]]\n"
     ]
    }
   ],
   "source": [
    "all_labels = set(true_labels).union( set(pred_lb) ) \n",
    "all_labels = list(all_labels)\n",
    "all_labels.sort()\n",
    "print all_labels \n",
    "conf = confusion_matrix(true_labels, pred_lb, labels=all_labels)\n",
    "print conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to manually print confusion matrix take set of both predicted and actual and iterate over both lists.\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels]+[5]) # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print \"    \" + empty_cell,\n",
    "    for label in labels: \n",
    "        print \"%{0}s\".format(columnwidth) % label,\n",
    "    print\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print \"    %{0}s\".format(columnwidth) % label1,\n",
    "        for j in range(len(labels)): \n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print cell,\n",
    "        print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ABOUT ACTOR    BE  HAVE    IN  INST\n",
      "    ABOUT  11.0   0.0   1.0   0.0   2.0   3.0\n",
      "    ACTOR   1.0  13.0   1.0   2.0   4.0   0.0\n",
      "       BE   0.0   0.0   5.0   1.0   1.0   1.0\n",
      "     HAVE   1.0   2.0   2.0   4.0   1.0   2.0\n",
      "       IN   3.0   3.0   4.0   4.0  10.0   3.0\n",
      "     INST   1.0   2.0   0.0   3.0   2.0   7.0\n"
     ]
    }
   ],
   "source": [
    "print_cm(conf,all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      |  A  A             |\n",
      "      |  B  C     H     I |\n",
      "      |  O  T     A     N |\n",
      "      |  U  O  B  V  I  S |\n",
      "      |  T  R  E  E  N  T |\n",
      "------+-------------------+\n",
      "ABOUT |<11> .  1  .  2  3 |\n",
      "ACTOR |  1<13> 1  2  4  . |\n",
      "   BE |  .  . <5> 1  1  1 |\n",
      " HAVE |  1  2  2 <4> 1  2 |\n",
      "   IN |  3  3  4  4<10> 3 |\n",
      " INST |  1  2  .  3  2 <7>|\n",
      "------+-------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm1 = ConfusionMatrix(true_labels,pred_lb)\n",
    "print cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more dataset:\n",
    "_/home/development/girish/datasets/NC-EN/SC08.all.txt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = df.values\n",
    "np.random.shuffle(data)\n",
    "df_ = pd.DataFrame(data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Singular-Plural noun mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Using predefined fix mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sources:**\n",
    "* [Plural Nouns Plus Worksheets: EnchantedLearning.com](http://www.enchantedlearning.com/grammar/partsofspeech/nouns/plurals/)\n",
    "* [A List of 100 Irregular Plural Nouns in English](https://www.thoughtco.com/irregular-plural-nouns-in-english-1692634)\n",
    "* []()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Source for list of singlular-to-plural nouns.\n",
    "url = 'http://www.enchantedlearning.com/grammar/partsofspeech/nouns/plurals/'\n",
    "\n",
    "r = requests.get( url )\n",
    "tables = pd.read_html(r.text, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of Noun</th>\n",
       "      <th>Rule for Forming the Plural</th>\n",
       "      <th>Examples</th>\n",
       "      <th>Exceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Word ends in s, x, ch, or sh</td>\n",
       "      <td>Add 'es' to the end</td>\n",
       "      <td>arch/arches, atlas/atlases, ax/axes, bash/bash...</td>\n",
       "      <td>axis/axes, ox/oxen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word ends in z</td>\n",
       "      <td>Add 'zes' to the end</td>\n",
       "      <td>buzz/buzzes, fizz/fizzes, klutz/klutzes, quiz/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ending in 'y' preceded by a vowel</td>\n",
       "      <td>Add an 's'</td>\n",
       "      <td>alley/alleys, attorney/attorneys, essay/essays...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ending in 'y' preceded by a consonant</td>\n",
       "      <td>Change the final 'y' to 'ies'</td>\n",
       "      <td>ally/allies, army/armies, baby/babies, beauty/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ends with 'f' or 'fe' (but not 'ff' or 'ffe')</td>\n",
       "      <td>Change the 'f' or 'fe' to 'ves'</td>\n",
       "      <td>calf/calves, elf/elves, half/halves, hoof/hoov...</td>\n",
       "      <td>belief/beliefs, chef/chefs, chief/chiefs, dwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ends with 'o'</td>\n",
       "      <td>Add 'es'</td>\n",
       "      <td>buffalo/buffaloes, cargo/cargoes, echo/echoes,...</td>\n",
       "      <td>albino/albinos, armadillo/armadillos, auto/aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Irregular</td>\n",
       "      <td>Variable</td>\n",
       "      <td>child/children, die/dice, foot/feet, goose/gee...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ends with 'is' (from a Greek root)</td>\n",
       "      <td>Change final 'is' to 'es'</td>\n",
       "      <td>analysis/analyses, axis/axes, basis/bases, cri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ends with 'us' (if the word is from the Latin)</td>\n",
       "      <td>Change final 'us' to 'i'</td>\n",
       "      <td>alumnus/alumni, bacillus/bacilli, cactus/cacti...</td>\n",
       "      <td>abacus/abacuses, crocus/crocuses, genus/genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ends with 'um'</td>\n",
       "      <td>Change final 'um' to 'a'</td>\n",
       "      <td>bacterium/bacteria, curriculum/curricula, datu...</td>\n",
       "      <td>album/albums, stadium/stadiums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ends with 'a' but not 'ia' (from a Latin root)</td>\n",
       "      <td>Change final 'a' to 'ae'</td>\n",
       "      <td>alga/algae, alumna/alumnae, antenna/antennae, ...</td>\n",
       "      <td>agenda/agendas, alfalfa/alfalfas, aurora/auror...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ends with 'on' (from a Greek root -- not 'tion')</td>\n",
       "      <td>Change final 'on' to 'a'</td>\n",
       "      <td>automaton/automata, criterion/criteria, phenom...</td>\n",
       "      <td>balloon/balloons, carton/cartons and many, man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ends with 'ex'</td>\n",
       "      <td>Change final 'ex' to 'ices'</td>\n",
       "      <td>vertex/vertices, vortex/vortices</td>\n",
       "      <td>annex/annexes, complex/complexes, duplex/duple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unchanging</td>\n",
       "      <td>Singular and plural are the same</td>\n",
       "      <td>advice, aircraft, bison, corn, deer, equipment...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Only the plural exists</td>\n",
       "      <td>Unchanging</td>\n",
       "      <td>barracks, bellows, cattle, congratulations, de...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Compound nouns</td>\n",
       "      <td>The plural ending is usually added to the main...</td>\n",
       "      <td>attorney general/attorneys general, bill of fa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Type of Noun  \\\n",
       "0                       Word ends in s, x, ch, or sh   \n",
       "1                                     Word ends in z   \n",
       "2                  Ending in 'y' preceded by a vowel   \n",
       "3              Ending in 'y' preceded by a consonant   \n",
       "4      Ends with 'f' or 'fe' (but not 'ff' or 'ffe')   \n",
       "5                                      Ends with 'o'   \n",
       "6                                          Irregular   \n",
       "7                 Ends with 'is' (from a Greek root)   \n",
       "8     Ends with 'us' (if the word is from the Latin)   \n",
       "9                                     Ends with 'um'   \n",
       "10    Ends with 'a' but not 'ia' (from a Latin root)   \n",
       "11  Ends with 'on' (from a Greek root -- not 'tion')   \n",
       "12                                    Ends with 'ex'   \n",
       "13                                        Unchanging   \n",
       "14                            Only the plural exists   \n",
       "15                                    Compound nouns   \n",
       "\n",
       "                          Rule for Forming the Plural  \\\n",
       "0                                 Add 'es' to the end   \n",
       "1                                Add 'zes' to the end   \n",
       "2                                          Add an 's'   \n",
       "3                       Change the final 'y' to 'ies'   \n",
       "4                     Change the 'f' or 'fe' to 'ves'   \n",
       "5                                            Add 'es'   \n",
       "6                                            Variable   \n",
       "7                           Change final 'is' to 'es'   \n",
       "8                            Change final 'us' to 'i'   \n",
       "9                            Change final 'um' to 'a'   \n",
       "10                           Change final 'a' to 'ae'   \n",
       "11                           Change final 'on' to 'a'   \n",
       "12                        Change final 'ex' to 'ices'   \n",
       "13                   Singular and plural are the same   \n",
       "14                                         Unchanging   \n",
       "15  The plural ending is usually added to the main...   \n",
       "\n",
       "                                             Examples  \\\n",
       "0   arch/arches, atlas/atlases, ax/axes, bash/bash...   \n",
       "1   buzz/buzzes, fizz/fizzes, klutz/klutzes, quiz/...   \n",
       "2   alley/alleys, attorney/attorneys, essay/essays...   \n",
       "3   ally/allies, army/armies, baby/babies, beauty/...   \n",
       "4   calf/calves, elf/elves, half/halves, hoof/hoov...   \n",
       "5   buffalo/buffaloes, cargo/cargoes, echo/echoes,...   \n",
       "6   child/children, die/dice, foot/feet, goose/gee...   \n",
       "7   analysis/analyses, axis/axes, basis/bases, cri...   \n",
       "8   alumnus/alumni, bacillus/bacilli, cactus/cacti...   \n",
       "9   bacterium/bacteria, curriculum/curricula, datu...   \n",
       "10  alga/algae, alumna/alumnae, antenna/antennae, ...   \n",
       "11  automaton/automata, criterion/criteria, phenom...   \n",
       "12                   vertex/vertices, vortex/vortices   \n",
       "13  advice, aircraft, bison, corn, deer, equipment...   \n",
       "14  barracks, bellows, cattle, congratulations, de...   \n",
       "15  attorney general/attorneys general, bill of fa...   \n",
       "\n",
       "                                           Exceptions  \n",
       "0                                  axis/axes, ox/oxen  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4   belief/beliefs, chef/chefs, chief/chiefs, dwar...  \n",
       "5   albino/albinos, armadillo/armadillos, auto/aut...  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8   abacus/abacuses, crocus/crocuses, genus/genera...  \n",
       "9                      album/albums, stadium/stadiums  \n",
       "10  agenda/agendas, alfalfa/alfalfas, aurora/auror...  \n",
       "11  balloon/balloons, carton/cartons and many, man...  \n",
       "12  annex/annexes, complex/complexes, duplex/duple...  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tables[5].values[0][2] = 'Hi'\n",
    "tables[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Using an library\n",
    "\n",
    "This doesn't work that good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import inflect\n",
    "\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man men\n",
      "men mens\n",
      "woman women\n",
      "women womens\n",
      "dog dogs\n",
      "cat cats\n",
      "flies fliess\n",
      "corpora corporas\n"
     ]
    }
   ],
   "source": [
    "for word in ['man', 'men', 'woman', 'women', 'dog', 'cat', 'flies', 'corpora']:\n",
    "    print word, p.plural_noun( word )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import inflect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'properties=%7B%22annotators%22%3A+%22tokenize%2Cssplit%2Cpos%2Cparse%22%2C+%22outputFormat%22%3A+%22json%22%7D'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = urllib.urlencode({'properties': '{\"annotators\": \"tokenize,ssplit,pos,parse\", \"outputFormat\": \"json\"}'})\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'properties=%7B%22annotators%22%3A+%22pos%22%2C+%22outputFormat%22%3A+%22json%22%7D'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = urllib.urlencode({'properties': '{\"annotators\": \"pos\", \"outputFormat\": \"json\"}'})\n",
    "url1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.post(url='http://10.129.2.170:9000/?' + url, \n",
    "              data='He failed to pay debt of the bank.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'sentences': [{u'basicDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'failed',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'He',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'},\n",
       "    {u'dep': u'mark',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'to',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'xcomp',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'pay',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'},\n",
       "    {u'dep': u'dobj',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u'debt',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'of',\n",
       "     u'governor': 8,\n",
       "     u'governorGloss': u'bank'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 8,\n",
       "     u'governorGloss': u'bank'},\n",
       "    {u'dep': u'nmod',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'bank',\n",
       "     u'governor': 5,\n",
       "     u'governorGloss': u'debt'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 9,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'}],\n",
       "   u'enhancedDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'failed',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'He',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'},\n",
       "    {u'dep': u'nsubj:xsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'He',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'mark',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'to',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'xcomp',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'pay',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'},\n",
       "    {u'dep': u'dobj',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u'debt',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'of',\n",
       "     u'governor': 8,\n",
       "     u'governorGloss': u'bank'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 8,\n",
       "     u'governorGloss': u'bank'},\n",
       "    {u'dep': u'nmod:of',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'bank',\n",
       "     u'governor': 5,\n",
       "     u'governorGloss': u'debt'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 9,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'}],\n",
       "   u'enhancedPlusPlusDependencies': [{u'dep': u'ROOT',\n",
       "     u'dependent': 2,\n",
       "     u'dependentGloss': u'failed',\n",
       "     u'governor': 0,\n",
       "     u'governorGloss': u'ROOT'},\n",
       "    {u'dep': u'nsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'He',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'},\n",
       "    {u'dep': u'nsubj:xsubj',\n",
       "     u'dependent': 1,\n",
       "     u'dependentGloss': u'He',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'mark',\n",
       "     u'dependent': 3,\n",
       "     u'dependentGloss': u'to',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'xcomp',\n",
       "     u'dependent': 4,\n",
       "     u'dependentGloss': u'pay',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'},\n",
       "    {u'dep': u'dobj',\n",
       "     u'dependent': 5,\n",
       "     u'dependentGloss': u'debt',\n",
       "     u'governor': 4,\n",
       "     u'governorGloss': u'pay'},\n",
       "    {u'dep': u'case',\n",
       "     u'dependent': 6,\n",
       "     u'dependentGloss': u'of',\n",
       "     u'governor': 8,\n",
       "     u'governorGloss': u'bank'},\n",
       "    {u'dep': u'det',\n",
       "     u'dependent': 7,\n",
       "     u'dependentGloss': u'the',\n",
       "     u'governor': 8,\n",
       "     u'governorGloss': u'bank'},\n",
       "    {u'dep': u'nmod:of',\n",
       "     u'dependent': 8,\n",
       "     u'dependentGloss': u'bank',\n",
       "     u'governor': 5,\n",
       "     u'governorGloss': u'debt'},\n",
       "    {u'dep': u'punct',\n",
       "     u'dependent': 9,\n",
       "     u'dependentGloss': u'.',\n",
       "     u'governor': 2,\n",
       "     u'governorGloss': u'failed'}],\n",
       "   u'index': 0,\n",
       "   u'parse': u'(ROOT\\n  (S\\n    (NP (PRP He))\\n    (VP (VBD failed)\\n      (S\\n        (VP (TO to)\\n          (VP (VB pay)\\n            (NP\\n              (NP (NN debt))\\n              (PP (IN of)\\n                (NP (DT the) (NN bank))))))))\\n    (. .)))',\n",
       "   u'tokens': [{u'after': u' ',\n",
       "     u'before': u'',\n",
       "     u'characterOffsetBegin': 0,\n",
       "     u'characterOffsetEnd': 2,\n",
       "     u'index': 1,\n",
       "     u'originalText': u'He',\n",
       "     u'pos': u'PRP',\n",
       "     u'word': u'He'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 3,\n",
       "     u'characterOffsetEnd': 9,\n",
       "     u'index': 2,\n",
       "     u'originalText': u'failed',\n",
       "     u'pos': u'VBD',\n",
       "     u'word': u'failed'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 10,\n",
       "     u'characterOffsetEnd': 12,\n",
       "     u'index': 3,\n",
       "     u'originalText': u'to',\n",
       "     u'pos': u'TO',\n",
       "     u'word': u'to'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 13,\n",
       "     u'characterOffsetEnd': 16,\n",
       "     u'index': 4,\n",
       "     u'originalText': u'pay',\n",
       "     u'pos': u'VB',\n",
       "     u'word': u'pay'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 17,\n",
       "     u'characterOffsetEnd': 21,\n",
       "     u'index': 5,\n",
       "     u'originalText': u'debt',\n",
       "     u'pos': u'NN',\n",
       "     u'word': u'debt'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 22,\n",
       "     u'characterOffsetEnd': 24,\n",
       "     u'index': 6,\n",
       "     u'originalText': u'of',\n",
       "     u'pos': u'IN',\n",
       "     u'word': u'of'},\n",
       "    {u'after': u' ',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 25,\n",
       "     u'characterOffsetEnd': 28,\n",
       "     u'index': 7,\n",
       "     u'originalText': u'the',\n",
       "     u'pos': u'DT',\n",
       "     u'word': u'the'},\n",
       "    {u'after': u'',\n",
       "     u'before': u' ',\n",
       "     u'characterOffsetBegin': 29,\n",
       "     u'characterOffsetEnd': 33,\n",
       "     u'index': 8,\n",
       "     u'originalText': u'bank',\n",
       "     u'pos': u'NN',\n",
       "     u'word': u'bank'},\n",
       "    {u'after': u'',\n",
       "     u'before': u'',\n",
       "     u'characterOffsetBegin': 33,\n",
       "     u'characterOffsetEnd': 34,\n",
       "     u'index': 9,\n",
       "     u'originalText': u'.',\n",
       "     u'pos': u'.',\n",
       "     u'word': u'.'}]}]}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'tokens',\n",
       " u'index',\n",
       " u'enhancedDependencies',\n",
       " u'basicDependencies',\n",
       " u'parse',\n",
       " u'enhancedPlusPlusDependencies']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['sentences'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'He', 1),\n",
       " (u'failed', 2),\n",
       " (u'to', 3),\n",
       " (u'pay', 4),\n",
       " (u'debt', 5),\n",
       " (u'of', 6),\n",
       " (u'the', 7),\n",
       " (u'bank', 8),\n",
       " (u'.', 9)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ob['word'], ob['index']) for ob in json_data['sentences'][0]['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'dep': u'ROOT',\n",
       "  u'dependent': 2,\n",
       "  u'dependentGloss': u'failed',\n",
       "  u'governor': 0,\n",
       "  u'governorGloss': u'ROOT'},\n",
       " {u'dep': u'nsubj',\n",
       "  u'dependent': 1,\n",
       "  u'dependentGloss': u'He',\n",
       "  u'governor': 2,\n",
       "  u'governorGloss': u'failed'},\n",
       " {u'dep': u'mark',\n",
       "  u'dependent': 3,\n",
       "  u'dependentGloss': u'to',\n",
       "  u'governor': 4,\n",
       "  u'governorGloss': u'pay'},\n",
       " {u'dep': u'xcomp',\n",
       "  u'dependent': 4,\n",
       "  u'dependentGloss': u'pay',\n",
       "  u'governor': 2,\n",
       "  u'governorGloss': u'failed'},\n",
       " {u'dep': u'dobj',\n",
       "  u'dependent': 5,\n",
       "  u'dependentGloss': u'debt',\n",
       "  u'governor': 4,\n",
       "  u'governorGloss': u'pay'},\n",
       " {u'dep': u'case',\n",
       "  u'dependent': 6,\n",
       "  u'dependentGloss': u'of',\n",
       "  u'governor': 8,\n",
       "  u'governorGloss': u'bank'},\n",
       " {u'dep': u'det',\n",
       "  u'dependent': 7,\n",
       "  u'dependentGloss': u'the',\n",
       "  u'governor': 8,\n",
       "  u'governorGloss': u'bank'},\n",
       " {u'dep': u'nmod',\n",
       "  u'dependent': 8,\n",
       "  u'dependentGloss': u'bank',\n",
       "  u'governor': 5,\n",
       "  u'governorGloss': u'debt'},\n",
       " {u'dep': u'punct',\n",
       "  u'dependent': 9,\n",
       "  u'dependentGloss': u'.',\n",
       "  u'governor': 2,\n",
       "  u'governorGloss': u'failed'}]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = json_data['sentences'][0]['basicDependencies']\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting features from sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verb_list = []\n",
    "for i in json_data['sentences'][0]['tokens']:\n",
    "    match = re.match(r'V(.*)',i['pos'])\n",
    "    if match:\n",
    "        verb_list.append(i['word'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'failed', u'pay']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding common ancestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns = []\n",
    "for i in json_data['sentences'][0]['tokens']:\n",
    "    match = re.match(r'NN(.*)',i['pos'])\n",
    "    if match:\n",
    "        nouns.append(i['word'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'debt', u'bank']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'dep': u'ROOT', u'dependent': 2, u'governorGloss': u'ROOT', u'governor': 0, u'dependentGloss': u'failed'}\n",
      "{u'dep': u'nsubj', u'dependent': 1, u'governorGloss': u'failed', u'governor': 2, u'dependentGloss': u'He'}\n",
      "{u'dep': u'mark', u'dependent': 3, u'governorGloss': u'pay', u'governor': 4, u'dependentGloss': u'to'}\n",
      "{u'dep': u'xcomp', u'dependent': 4, u'governorGloss': u'failed', u'governor': 2, u'dependentGloss': u'pay'}\n",
      "{u'dep': u'dobj', u'dependent': 5, u'governorGloss': u'pay', u'governor': 4, u'dependentGloss': u'debt'}\n",
      "{u'dep': u'case', u'dependent': 6, u'governorGloss': u'bank', u'governor': 8, u'dependentGloss': u'of'}\n",
      "{u'dep': u'det', u'dependent': 7, u'governorGloss': u'bank', u'governor': 8, u'dependentGloss': u'the'}\n",
      "{u'dep': u'nmod', u'dependent': 8, u'governorGloss': u'debt', u'governor': 5, u'dependentGloss': u'bank'}\n",
      "{u'dep': u'punct', u'dependent': 9, u'governorGloss': u'failed', u'governor': 2, u'dependentGloss': u'.'}\n"
     ]
    }
   ],
   "source": [
    "for i in tree:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path from NN to ROOT\n",
    "path_head = []\n",
    "dependancy_head = []\n",
    "words = 'debt'\n",
    "while (words!='ROOT'):\n",
    "    for (idx,i) in enumerate(tree):\n",
    "        if i['dependentGloss']==words:\n",
    "            path_head.append(i['dependentGloss'])\n",
    "            dependancy_head.append(i['dep'])\n",
    "            words = i['governorGloss'] \n",
    "            index = idx\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path from NN to ROOT\n",
    "path_mod = []\n",
    "dependancy_mod = []\n",
    "words = 'bank'\n",
    "while (words!='ROOT'):\n",
    "    for (idx,i) in enumerate(tree):\n",
    "        if i['dependentGloss']==words:\n",
    "            path_mod.append(i['dependentGloss'])\n",
    "            dependancy_mod.append(i['dep'])\n",
    "            words = i['governorGloss'] \n",
    "            index = idx\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'debt', u'pay', u'failed']\n",
      "[u'bank', u'debt', u'pay', u'failed']\n",
      "[u'dobj', u'xcomp', u'ROOT']\n",
      "[u'nmod', u'dobj', u'xcomp', u'ROOT']\n"
     ]
    }
   ],
   "source": [
    "print path_head\n",
    "print path_mod\n",
    "print dependancy_head\n",
    "print dependancy_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'debt', u'dobj'), (u'pay', u'xcomp'), (u'failed', u'ROOT')]\n",
      "[(u'bank', u'nmod'), (u'debt', u'dobj'), (u'pay', u'xcomp'), (u'failed', u'ROOT')]\n"
     ]
    }
   ],
   "source": [
    "res_head = zip(path_head,dependancy_head)\n",
    "res_mod = zip(path_mod,dependancy_mod)\n",
    "print res_head\n",
    "print res_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt\n",
      "ROOT\n",
      "nmod\n"
     ]
    }
   ],
   "source": [
    "#common ancestor\n",
    "flag=0\n",
    "for i in res_head:\n",
    "    if(flag==0):\n",
    "        for j in res_mod:\n",
    "            if i[0]==j[0]:\n",
    "                print i[0]\n",
    "                print rel1\n",
    "                print rel2\n",
    "                flag=1\n",
    "                break\n",
    "            else:\n",
    "                rel2 = j[1]\n",
    "    rel1 = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which takes a noun compound (i.e., \"student protest\", \"bank debt\", \"debt bank\", etc) and a setence (\"Thousands of students participated in series of protest in JNU.\", \"He failed to pay debt of a bank.\") as inputs. It should return the common ancestor $c$ of the head and the modifier, dependency from $c$ towards the head, and dependecy from $c$ toards the modifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {
    "height": "46px",
    "width": "212px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "230px",
    "left": "1325.25px",
    "right": "15.1px",
    "top": "108.984px",
    "width": "183px"
   },
   "toc_section_display": "none",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
